# -*- coding: utf-8 -*-
"""
Matthew Allcock
"""

"""
Each strategy consists of a redrawing rule. Each strategy has a corresponding
function which returns a boolean answer to the question: Draw again?
"""

import numpy as np
from scipy.special import erf
from scipy.optimize import newton
import scipy.stats as stats

def to_redraw(strategy, dist_type, dist_params, penalty, draws):
    ########### Perfect information - strategies using optimal stopping theory
    if strategy == "perfect":
        if dist_type == "uniform":
            # Optimal stopping rule can be calculated analytically.
            [a, b] = dist_params
            midpoint = 0.5*(a + b)
            if penalty <= midpoint:
                V = b - np.sqrt(2*(b-a)*penalty)
            else:
                V = -penalty + midpoint
    
        elif dist_type == "lomax":
            # Optimal stopping rule can be calculated analytically.
            [alpha, xm, lamb] = dist_params
            threshold = lamb/(alpha - 1)
            if penalty <= threshold:
                V = (lamb**alpha/(penalty*(alpha - 1)))**(1/(alpha - 1))
            else:
                V = -penalty + threshold
        
        elif dist_type == "normal":
            # Optimal stopping rule cannot be calculated analytically.
            # So we use secant method to solve numerically
            [mu, sigma] = dist_params
            def optimal_function(y):
                return (1/np.sqrt(np.pi)*np.exp(-y**2) - y*(1 - erf(y))
                        - np.sqrt(2)*penalty/sigma)
            root = newton(optimal_function, 0)
            V = np.sqrt(2)*sigma*root + mu

        if draws[-1] >= V:
            redraw = False
        else:
            redraw = True
    
    elif strategy == "partial":
        ########### Partial information - strategies use maximum likelihood theory
        if dist_type == "uniform":
            raise ValueError("Haven't coded this strategy yet")
        elif dist_type == "lomax":
            #Find MLE params based on previous draws.
            [alphan, xmn, lambn] = stats.pareto.fit(draws)
            if alphan <= 1:
                raise ValueError("alphan <= 1")
            else:
                Mn = max(draws)
                #expected gain from drawing
                exp_draw = (Mn + lambn)/((alphan - 1)*(1 + Mn/lambn)**alphan)
                if exp_draw > penalty:
                    redraw = True
                else:
                    redraw = False
        elif dist_type == "normal":
            if len(draws) == 1:
                redraw = True
            else:
                mu_sample = np.mean(draws)
                sigma_sample = np.std(draws)
                max_draw = max(draws)
                
                yMn = (max_draw - mu_sample)/(np.sqrt(2)*sigma_sample)
                Pn = (1 - erf(yMn))/2
                exp_gain = Pn*(mu_sample - max_draw) + (sigma_sample/np.sqrt(2*np.pi))*np.exp(-yMn**2)
                # exp_gain is derived analytically
                if exp_gain >= penalty:
                    redraw = True
                else:
                    redraw = False
    return redraw
